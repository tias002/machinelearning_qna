<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
    <link rel="stylesheet" href="style.css">
    <title>Question and answers</title>
</head>
<body>

    
  
  <div class="main-container">
    <h1>Questions & answers of machine learning </h1>

    <div class="wrap">
      <h1 class="wrap-title">
      What is the difference between supervised and 
      unsupervised machine learning?
     </h1>

     <p class="wrap-text">
      Supervised learning requires training labeled data. 
      For example, in order to do classification 
      (a supervised learning task), you’ll need to first 
      label the data you’ll use to train the model to 
      classify data into your labeled groups. 
      Unsupervised learning, in contrast, does not 
      require labeling data explicitly.
      <a href="https://www.springboard.com/blog/ai-machine-learning/machine-learning-interview-questions/">read more</a></p>
      <button class="wrap-toggle">
        <i class="fas fa-chevron-circle-down"></i>
        <i class="fas fa-times"></i>
      </button>
   </div>
    

   <div class="wrap">
      <h1 class="wrap-title">
        How is KNN different from k-means clustering?
     </h1>
     <p class="wrap-text">
      K-Nearest Neighbors is a supervised classification 
      algorithm, while k-means clustering is an 
      unsupervised clustering algorithm. what this 
      really means is that in order for K-Nearest Neighbors 
      to work, you need labeled data you want to classify an 
      unlabeled point into (thus the nearest neighbor part). 
      K-means clustering requires only a set of unlabeled 
      points and a threshold: the algorithm will take 
      unlabeled points and gradually learn how to cluster 
      them into groups by computing the mean of the distance 
      between different points.<a href="https://www.springboard.com/blog/ai-machine-learning/machine-learning-interview-questions/">read more</a></p>
      <button class="wrap-toggle">
        <i class="fas fa-chevron-circle-down"></i>
        <i class="fas fa-times"></i>
       </button>
    </div>
    
    <div class="wrap">
      <h1 class="wrap-title">
        Explain how a ROC curve works.
     </h1>
     <p class="wrap-text">
      The ROC curve is a graphical representation of the 
      contrast between true positive rates and the false 
      positive rate at various thresholds. It’s often used as
      a proxy for the trade-off between the sensitivity of 
      the model (true positives) vs the fall-out or the 
      probability it will trigger a false alarm 
      (false positives).<a href="https://www.springboard.com/blog/ai-machine-learning/machine-learning-interview-questions/">read more</a></p>
      <button class="wrap-toggle">
        <i class="fas fa-chevron-circle-down"></i>
        <i class="fas fa-times"></i>
       </button>
    </div> 
   
    <div class="wrap">
      <h1 class="wrap-title">
        Define precision and recall.
     </h1>
     <p class="wrap-text">
      the amount of positives your model claims compared 
      to the actual number of positives there are 
      throughout the data. Precision is also known as the 
      positive predictive value, and it is a measure of 
      the amount of accurate positives your model claims 
      compared to the number of positives it actually 
      claims. It can be easier to think of recall and 
      precision in the context of a case where you’ve 
      predicted that there were 10 apples and 5 oranges 
      in a case of 10 apples. You’d have perfect recall 
      (there are actually 10 apples, and you predicted 
      there would be 10) but 66.7% precision because out 
      of the 15 events you predicted, only 10 (the apples)
       are correct.<a href="https://www.springboard.com/blog/ai-machine-learning/machine-learning-interview-questions/">read more</a></p>
       <button class="wrap-toggle">
        <i class="fas fa-chevron-circle-down"></i>
        <i class="fas fa-times"></i>
       </button>
    </div>   
    
    

    <div class="wrap">
      <h1 class="wrap-title">
        Explain the difference between L1 and L2 regularization.
     </h1>
     <p class="wrap-text">
      L2 regularization tends to spread error among all 
      the terms, while L1 is more binary/sparse, with many 
      variables either being assigned a 1 or 0 in weighting. 
      L1 corresponds to setting a Laplacean prior on the 
      terms, while L2 corresponds to a 
      Gaussian prior.<a href="https://www.springboard.com/blog/ai-machine-learning/machine-learning-interview-questions/">read more</a></p>
      <button class="wrap-toggle">
        <i class="fas fa-chevron-circle-down"></i>
        <i class="fas fa-times"></i>
      </button>
    </div>
 </div>

  <script src="app.js"></script>
</body>
</html>